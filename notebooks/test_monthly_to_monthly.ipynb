{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../csv/ord_vol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flake8: noqa: E501\n",
    "\n",
    "import numpy as np\n",
    "from numpy.core.fromnumeric import mean\n",
    "import pandas as pd\n",
    "from pandas.core.indexes.api import get_objs_combined_axis\n",
    "import pmdarima\n",
    "from datetime import datetime\n",
    "import typing\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error # upgrade to the the latest scikit-learn pip install -U scikit-learn\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class ModelWrapper(ABC):\n",
    "    def __init__(self, **kwargs):\n",
    "        try:\n",
    "            self.__model = kwargs['model']\n",
    "        except:\n",
    "            self.__model = None\n",
    "        \n",
    "    @abstractmethod\n",
    "    def fit(self, x):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, n):\n",
    "        pass\n",
    "    def get_model(self):\n",
    "        return self.__model\n",
    "    def __str__(self):\n",
    "        return \"ModelWrapper for '{}'\".format(str(self.__model))\n",
    "\n",
    "\n",
    "class AutoArimaWrapper(ModelWrapper):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__kwargs = kwargs\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def fit(self, y: typing.Union[list, np.array]):\n",
    "        kwargs = self.__kwargs.copy()\n",
    "        try:\n",
    "            kwargs.pop('y')\n",
    "        except:\n",
    "            pass\n",
    "        self.__model = pmdarima.auto_arima(y=y, **kwargs)\n",
    "\n",
    "    def predict(self, *args, **kwargs):\n",
    "        return self.__model.predict(*args, **kwargs)\n",
    "\n",
    "    def get_conf_int(self, *args, **kwargs):\n",
    "        _, conf_int = self.__model.predict(*args, return_conf_int=True, **kwargs)\n",
    "        return conf_int\n",
    "\n",
    "class KerasWrapper(ModelWrapper):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "class ProphetWrapper(ModelWrapper):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__kwargs = kwargs\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def fit(self, y: typing.Union[list, np.array]):\n",
    "        kwargs = self.__kwargs.copy()\n",
    "        train = pd.DataFrame(data={'y': y},)\n",
    "        self.__model = pmdarima.auto_arima(y=y, **kwargs)\n",
    "\n",
    "    def predict(self, *args, **kwargs):\n",
    "        return self.__model.predict(*args, **kwargs)\n",
    "\n",
    "    def get_conf_int(self, *args, **kwargs):\n",
    "        _, conf_int = self.__model.predict(*args, return_conf_int=True, **kwargs)\n",
    "        return conf_int\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Changes to be made\n",
    "## 1 would like to add an argument \n",
    "\n",
    "class TSFM(object):\n",
    "    def __init__(self,\n",
    "                 df: pd.core.frame.DataFrame, #df is now daily data\n",
    "                 n_pred_period: int,\n",
    "                 date_variable: typing.Union[int, str],\n",
    "                 target_variable: typing.Union[int, str],\n",
    "                 value_variable: typing.Union[int, str],\n",
    "                 stop_date: str,         # stop date of train set, to split df to train and test sets\n",
    "                 input_is_monthly: bool, \n",
    "                 output_is_monthly: bool,\n",
    "                 model_wrapper: ModelWrapper = None,\n",
    "                 section_list: list = None,\n",
    "                 alpha: float = 0.05,):\n",
    "                #  stepwise: bool = True,\n",
    "                # cycle_length: int = 12,\n",
    "                #  start_order: tuple = (0, 1, 0),\n",
    "                #  max_order: tuple = (4, 2, 5),\n",
    "                #  start_seasonal_order: tuple = (0, 1, 0),\n",
    "                #  max_seasonal_order: tuple = (2, 2, 4)):\n",
    "        self.target_variable = target_variable\n",
    "        # self.n_pred_period = n_pred_period + abs((datetime.strptime(df[date_variable].to_numpy()[-1])  - datetime.strptime(stop_date, \"%Y-%m-%d\")).days)\n",
    "        self.n_pred_period = n_pred_period\n",
    "        self.stop_date = stop_date\n",
    "        self.model_wrapper = model_wrapper\n",
    "        self.input_is_monthly = input_is_monthly\n",
    "        self.output_is_monthly = output_is_monthly\n",
    "        self.alpha = alpha\n",
    "        # self.stepwise = stepwise\n",
    "        # self.start_order = start_order\n",
    "        # self.max_order = max_order\n",
    "        # self.start_seasonal_order = start_seasonal_order\n",
    "        # self.max_seasonal_order = max_seasonal_order\n",
    "\n",
    "        self.is_log_transformed_dict = dict()\n",
    "        self.pred_dict = dict()\n",
    "        self.pred_ic_dict = dict()\n",
    "        self.adjusted_pred_dict = dict()\n",
    "        self.adjusted_pred_ic_dict = dict()\n",
    "\n",
    "        # train and test df must have date as index, and 2 columns: sections(e.g. territory) and values(e.g. order_volume)\n",
    "        if type(date_variable) is int:\n",
    "            date_variable = df.columns[date_variable]\n",
    "        if type(value_variable) is int:\n",
    "            value_variable = df.columns[value_variable]\n",
    "        if type(target_variable) is int:\n",
    "            target_variable = df.columns[target_variable]\n",
    "        # Select relevant columns for train and test df, create empty pred df\n",
    "        self.columns = [date_variable, target_variable, value_variable]\n",
    "        df[self.columns[0]] = pd.to_datetime(df[self.columns[0]])\n",
    "        \n",
    "\n",
    "        \n",
    "        if input_is_monthly and not output_is_monthly:\n",
    "            print(\"Monthly to daily is not yet supported\")\n",
    "            return\n",
    "        self.df = df.copy()\n",
    "\n",
    "        if self.model_wrapper is None:\n",
    "            print(\"Model wrapper is None, no model is trained.\")\n",
    "            return\n",
    "\n",
    "        # keys: sections(territories), value: list(train, test, pred), for easy storing and fetching data\n",
    "        self.df_dict = dict()\n",
    "        self.model_dict = dict()\n",
    "        self.adjusted_model_dict = dict()\n",
    "\n",
    "        # Iterate through the unique sections\n",
    "        self.section_list = section_list\n",
    "        if self.section_list is None:\n",
    "            self.section_list = df[target_variable].unique()\n",
    "        for section in self.section_list:\n",
    "            self.is_log_transformed_dict[section] = False\n",
    "            models = self.__train_models(section = section)\n",
    "            if self.__have_negative_prediction(models=models):\n",
    "                print(\"Negative prediction detected in\", section)\n",
    "                self.is_log_transformed_dict[section] = True\n",
    "                models = self.__train_models(section = section)\n",
    "            (model, adjusted_model) = models\n",
    "            self.model_dict[section] = model\n",
    "            self.adjusted_model_dict[section] = adjusted_model\n",
    "            self.pred_dict[section], self.pred_ic_dict[section] = self.__get_pred_data(section=section, return_conf_int=True, is_adjusted=False)\n",
    "            self.adjusted_pred_dict[section], self.adjusted_pred_ic_dict[section] = self.__get_pred_data(section=section, return_conf_int=True, is_adjusted=True)\n",
    "\n",
    "    # DF Getters--------------------------------------------------------------\n",
    "    def get_actual_data(self, section: str, is_adjusted: bool, is_log_transformed: bool = None) -> pd.core.frame.DataFrame:\n",
    "        '''\n",
    "        Returns the input data of a section with or without transformations.\n",
    "        * section: str: an element in the unique list of target variables.\n",
    "        * is_adjusted: bool: determine if the returning data is adjusted by the anomally filter.\n",
    "        * is_log_transformed: bool = None: determine if the returning data is log transformed. If is None then it's value is determined by self.is_log_transformed_dict[section]\n",
    "        '''\n",
    "        agg_df = self.df[self.columns].groupby(self.columns[0:2], as_index=False).sum().copy()\n",
    "        agg_df = agg_df.query(self.columns[1] + \"==\" + \"'\" + section + \"'\")[[self.columns[0], self.columns[2]]]\n",
    "        # agg_df.set_index(self.columns[0], inplace=True)\n",
    "        if not self.input_is_monthly and self.output_is_monthly:\n",
    "            full_daily_df, remainder_daily_df = self.get_full_month_data(df=agg_df.copy())\n",
    "            agg_df = TSFM.to_monthly(full_daily_df.set_index(self.columns[0], inplace=False)).reset_index(inplace=False)\n",
    "        if is_adjusted and self.output_is_monthly:\n",
    "            agg_df = self.anomaly_filter(agg_df, alpha = self.alpha)\n",
    "        if is_log_transformed is None:\n",
    "            try:\n",
    "                is_log_transformed = self.is_log_transformed_dict[section]\n",
    "            except:\n",
    "                is_log_transformed = False\n",
    "        if is_log_transformed and self.model_wrapper is not None:\n",
    "            agg_df = TSFM.log_transform(agg_df)\n",
    "        return agg_df\n",
    "\n",
    "    def get_train_data(self, section: str):\n",
    "        '''\n",
    "        Returns the training data for the anomaly filter method.\n",
    "        * section: str: an element in the unique list of target variables.\n",
    "        '''\n",
    "        actual_df = self.get_actual_data(section, is_adjusted=False)\n",
    "        return actual_df.iloc[lambda x: x.index <= self.stop_date].copy()\n",
    "\n",
    "    def get_test_data(self, section: str, ):\n",
    "        actual_df = self.get_actual_data(section, is_adjusted=False)\n",
    "        return actual_df.iloc[lambda x: x.index > self.stop_date].copy()\n",
    "\n",
    "    def get_pred_data(self, section: str, is_adjusted: bool, return_conf_int: bool = False):\n",
    "        pred, ic = None, None\n",
    "        if is_adjusted:\n",
    "            pred, ic = self.adjusted_pred_dict[section], self.adjusted_pred_ic_dict[section]\n",
    "        else:\n",
    "            pred, ic = self.pred_dict[section], self.pred_ic_dict[section]\n",
    "        if return_conf_int:\n",
    "            return pred, ic\n",
    "        return pred\n",
    "\n",
    "    def get_full_month_data(self, df):\n",
    "        max_date = df[self.columns[0]].max()\n",
    "        if self.__is_last_day_of_month(max_date):\n",
    "            return df, None\n",
    "        new_date =  max_date.year + '-' + max_date.month + '-' + max_date.day\n",
    "        return df.query(self.columns[0] + \"<'\" + new_date + \"'\"), df.query(self.columns[0] + \">='\" + new_date + \"'\")\n",
    "        \n",
    "\n",
    "    def __is_last_day_of_month(self, date):\n",
    "        next_day = date + pd.DateOffset(days=1)\n",
    "        if date.month == next_day.month:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def __get_pred_data(self, section: str, return_conf_int: bool = False, is_adjusted: bool = True):\n",
    "        actual_df = self.get_actual_data(section, False)\n",
    "        model = self.get_model(section=section, is_adjusted=is_adjusted)\n",
    "        if self.output_is_monthly:\n",
    "            freq = 'MS'\n",
    "        else:\n",
    "            freq = 'D'\n",
    "        if model is None:\n",
    "            print(\"Model of\", section, \"section was not initiated. Might due to insufficient training data.\")\n",
    "            return None\n",
    "        pred  = model.predict(self.n_pred_period)\n",
    "        conf_int = model.get_conf_int(self.n_pred_period)\n",
    "        temp_pred_df = pd.DataFrame(\n",
    "            data={\n",
    "                self.columns[0]: pd.date_range(max(actual_df[self.columns[0]]),freq=freq,periods=self.n_pred_period+1)[1:],\n",
    "                self.columns[1]: [section for x in range(len(pred))],\n",
    "                self.columns[-1]: pred})  # Use numbers inplace of future dates for now)\n",
    "        temp_pred_df = temp_pred_df[[self.columns[0], self.columns[2]]]\n",
    "        # temp_pred_df.set_index(self.columns[0], inplace=True)\n",
    "        if self.is_log_transformed_dict[section]:\n",
    "            temp_pred_df = self.exp_transform(temp_pred_df)\n",
    "        if return_conf_int:\n",
    "            return temp_pred_df.copy(), conf_int\n",
    "        return temp_pred_df.copy()\n",
    "\n",
    "    def get_pred_df(self):\n",
    "        '''\n",
    "        function to be called in the backend to get pred data from all sections\n",
    "        '''\n",
    "        return_df = pd.DataFrame(columns=self.columns)\n",
    "        for section in self.section_list:\n",
    "            actual_pred = self.get_pred_data(section, is_adjusted=False)\n",
    "            adjusted_actual_pred = self.get_pred_data(section, is_adjusted=True)\n",
    "            pred = pd.DataFrame(data={actual_pred.columns[0]: actual_pred[actual_pred.columns[0]].to_numpy(), \"value2\": adjusted_actual_pred[adjusted_actual_pred.columns[0]].to_numpy()},\n",
    "                                index = actual_pred.index)\n",
    "            # pred.reset_index(inplace=True)\n",
    "            pred[self.target_variable] = [section for x in range(pred.shape[0])]\n",
    "            return_df = return_df.append(pred, ignore_index=True)\n",
    "        return_df.sort_values(by=[self.columns[1], self.columns[0]], inplace=True, ignore_index=True)\n",
    "        return return_df\n",
    "\n",
    "    # Model Getters----------------------------------------------------------\n",
    "    def get_model(self, section: str, is_adjusted: bool):\n",
    "        if is_adjusted:\n",
    "            return self.adjusted_model_dict[section]\n",
    "        return self.model_dict[section]\n",
    "    \n",
    "    # Plot Function-----------------------------------------------------------\n",
    "    def plot(self, section: str):\n",
    "        actual = self.get_actual_data(section, is_adjusted=False)\n",
    "        adjusted_actual, conf_int_df = self.anomaly_filter(actual, return_conf_int=True, alpha = self.alpha)\n",
    "\n",
    "        actual.set_index(self.columns[0], inplace=True)\n",
    "        adjusted_actual.set_index(self.columns[0], inplace=True) \n",
    "        conf_int_df.set_index(self.columns[0], inplace=True)\n",
    "        # pred, ci = self.get_pred_data(section, return_conf_int=True)\n",
    "\n",
    "        actual_pred = self.get_pred_data(section, is_adjusted=False)\n",
    "        adjusted_actual_pred = self.get_pred_data(section, is_adjusted=True)\n",
    "\n",
    "        actual_pred.set_index(self.columns[0], inplace=True)\n",
    "        adjusted_actual_pred.set_index(self.columns[0], inplace=True)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(14,6))\n",
    "        ax.plot(actual.index, actual[actual.columns[0]].to_numpy(),label=\"Actual\")   #Actuals This should come from original DS (all actuals)\n",
    "        ax.plot(adjusted_actual.index, adjusted_actual[adjusted_actual.columns[0]].to_numpy(),'-g', label=\"Adjusted Actual\")   \n",
    "        # ax.plot(pred.index, pred[pred.columns[0]], '-r',alpha=0.75,label=\"Forecast\")  ## Pred\n",
    "        ax.fill_between(conf_int_df.index, conf_int_df.iloc[:, 0], conf_int_df.iloc[:, 1],alpha=0.3, color='b')  ## Conf intervals\n",
    "        \n",
    "        ax.plot(actual_pred.index, actual_pred.iloc[:, 0], '--b',alpha=0.75,label=\"Actual Forecast\")\n",
    "        ax.plot(adjusted_actual_pred.index, adjusted_actual_pred.iloc[:, 0], '--g',alpha=0.75,label=\"Adjusted Actual Forecast\")\n",
    "        plt.title('Forecast Model')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Forecast Accurary')\n",
    "\n",
    "        ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "        ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def anomaly_filter(self,\n",
    "                       df: pd.core.frame.DataFrame,\n",
    "                       return_conf_int: bool = False, \n",
    "                       n_rolling_period: int = 12,\n",
    "                       alpha: float = 0.05):\n",
    "        print(\"Applying anomaly filter...\")\n",
    "        df = df.copy()\n",
    "        df.set_index(self.columns[0], inplace=True)\n",
    "        train = df.iloc[lambda x: x.index <= self.stop_date]\n",
    "        returning_ic_list = list()\n",
    "        (start_p, start_d, start_q) = (0, 1, 0)\n",
    "        (max_p, max_d, max_q) = (4, 2, 5)\n",
    "        (start_P, start_D, start_Q) = (0, 1, 0)\n",
    "        (max_P, max_D, max_Q) = (2, 2, 4)\n",
    "        for i in range(train.shape[0], df.shape[0], n_rolling_period):\n",
    "            arima_model = pmdarima.auto_arima(train[train.columns[0]],\n",
    "                                                start_p=start_p, start_P=start_P,\n",
    "                                                start_q=start_q, start_Q=start_Q,\n",
    "                                                d=start_d, D=start_D,\n",
    "                                                max_p=max_p, max_P=max_P,\n",
    "                                                max_d=max_d, max_D=max_D,\n",
    "                                                max_q=max_q, max_Q=max_Q,\n",
    "                                                trace=True, m=12, stepwise=True)\n",
    "            temp_actual_df = df.iloc[i:min(i+n_rolling_period, df.shape[0]), :].copy()\n",
    "            temp_pred, ic_list = arima_model.predict(n_rolling_period, return_conf_int=True, alpha=alpha)\n",
    "            print(\"ic_list\", ic_list)\n",
    "            for j in range(temp_actual_df.shape[0]):\n",
    "                temp_actual = temp_actual_df.iloc[j, 0]\n",
    "                ic = ic_list[j]\n",
    "                if temp_actual < ic[0] or temp_actual > ic[1]:\n",
    "                    temp_actual_df.iloc[j, 0] = temp_pred[j]\n",
    "            train = train.append(temp_actual_df)\n",
    "            returning_ic_list = returning_ic_list + ic_list.tolist()\n",
    "        train[train.columns[0]] = train[train.columns[0]].astype('float')\n",
    "        train = train.asfreq('MS')\n",
    "        if return_conf_int:\n",
    "            returning_ic_list = np.array(returning_ic_list)\n",
    "            print(\"returning_ic_list\", returning_ic_list)\n",
    "            ic_df = pd.DataFrame(\n",
    "                data={\n",
    "                    'lower': returning_ic_list[:, 0],\n",
    "                    'upper': returning_ic_list[:, 1],\n",
    "                },\n",
    "                index=pd.Index(data=pd.date_range(self.stop_date,freq='MS',periods=returning_ic_list.shape[0]+1)[1:], name=self.columns[0])\n",
    "            )\n",
    "            return train.reset_index(inplace=False).copy(), ic_df.reset_index(inplace=False).copy()\n",
    "        return train.reset_index(inplace=False).copy()\n",
    "    \n",
    "    def cross_validate(self,section: str, is_adjusted: bool):\n",
    "        actual_df = self.get_actual_data(section, is_adjusted)\n",
    "        actual_arr = actual_df[actual_df.columns[0]].to_numpy(dtype='float')\n",
    "        trained_model = self.get_model(section, is_adjusted)\n",
    "        order = trained_model.order\n",
    "        seasonal_order = trained_model.seasonal_order\n",
    "\n",
    "        model = copy.copy(self.model_wrapper)\n",
    "        MAE = list()\n",
    "        MAPE = list()\n",
    "        tscv = TimeSeriesSplit(10)\n",
    "        for train_index, test_index in tscv.split(X=actual_df.index):\n",
    "            if len(train_index) >= 24:\n",
    "                print(\"train_index = {}\".format(train_index))\n",
    "                print(\"test_index = {}\".format(test_index))\n",
    "                train = actual_arr[train_index]\n",
    "                test = actual_arr[test_index]\n",
    "                print(\"train = {}\".format(train))\n",
    "                print(\"test = {}\".format(test))\n",
    "                model.fit(train)\n",
    "                pred = model.predict(len(test))\n",
    "                mae = mean_absolute_error(test, pred)\n",
    "                mape = mean_absolute_percentage_error(test, pred)\n",
    "                MAE.append(mae)\n",
    "                MAPE.append(mape)\n",
    "                \n",
    "                print(\"MAE = {}\".format(mae))\n",
    "                print(\"MAPE = {}\".format(mape))\n",
    "                print(\"-\"*50)\n",
    "            else:\n",
    "                pass\n",
    "        print(\"MAE = {}\".format(MAE))\n",
    "        print(\"MAPE = {}\".format(MAPE))\n",
    "        print(\"Average MAE = {}\".format(np.mean(MAE)))\n",
    "        print(\"Average MAPE = {}\".format(np.mean(MAPE)))\n",
    "\n",
    "    def __train_models(self, section: str) -> tuple:\n",
    "        # (start_p, start_d, start_q) = self.start_order\n",
    "        # (max_p, max_d, max_q) = self.max_order\n",
    "        # (start_P, start_D, start_Q) = self.start_seasonal_order\n",
    "        # (max_P, max_D, max_Q) = self.max_seasonal_order\n",
    "    \n",
    "        print(\"Inspecting\", section, \"...\")\n",
    "        temp_actual_df = self.get_actual_data(section=section, is_adjusted=False, is_log_transformed=self.is_log_transformed_dict[section])\n",
    "        temp_adjusted_actual_df = self.get_actual_data(section=section, is_adjusted=True, is_log_transformed=self.is_log_transformed_dict[section])\n",
    "        if temp_actual_df.shape[0] >= 2 * 12:\n",
    "            # train actual data\n",
    "            print(\"Training\", temp_actual_df.shape[0], \"actual records ...\")\n",
    "            model_wrapper = copy.copy(self.model_wrapper)\n",
    "            model_wrapper.fit(temp_actual_df[temp_actual_df.columns[-1]])\n",
    "\n",
    "            # train adjusted actual data\n",
    "            print(\"Training\", temp_adjusted_actual_df.shape[0], \"adjusted actual records ...\")\n",
    "            adjusted_model_wrapper = copy.copy(self.model_wrapper)\n",
    "            adjusted_model_wrapper.fit(temp_adjusted_actual_df[temp_adjusted_actual_df.columns[-1]])\n",
    "            return model_wrapper, adjusted_model_wrapper\n",
    "        print(\"Number of data points in Section\", section, \"is too small (\" + str(\n",
    "            temp_actual_df.shape[0]) + \". Must be at least twice the declared cycle length.\")\n",
    "        return None, None\n",
    "\n",
    "    def __have_negative_prediction(self, models: tuple) -> bool:\n",
    "        (model, adjusted_model) = models\n",
    "        if model is None or adjusted_model is None:\n",
    "            return False\n",
    "        pred = model.predict(self.n_pred_period)\n",
    "        adjusted_pred = adjusted_model.predict(self.n_pred_period)\n",
    "        if min(min(pred), min(adjusted_pred)) < 0:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def log_transform(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "        '''\n",
    "        df has 1 value column and has dates as indeces\n",
    "        '''\n",
    "        value_arr = df.loc[:, df.columns[0]].values.copy()\n",
    "        value_arr[value_arr < 1] = 1 # avoid negative results from transformation\n",
    "        value_arr = np.log(value_arr)\n",
    "        return  pd.DataFrame(index=df.index, data={df.columns[0]: value_arr})\n",
    "    \n",
    "    @staticmethod\n",
    "    def exp_transform(df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "        '''\n",
    "        df has 1 value column and has dates as indeces\n",
    "        '''\n",
    "        value_arr = df.loc[:, df.columns[0]].values.copy()\n",
    "        value_arr = np.exp(value_arr)\n",
    "        return  pd.DataFrame(index=df.index, data={df.columns[0]: value_arr})\n",
    "\n",
    "    @classmethod\n",
    "    def to_monthly(cls, df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "        return df.resample('MS').sum()\n",
    "\n",
    "    def foo():\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima_wrapper = AutoArimaWrapper(start_p=0, start_P=0,\n",
    "                                        d=1, D=1,\n",
    "                                        start_q=0, start_Q=0,\n",
    "                                        max_p=4, max_P=2,\n",
    "                                        max_d=2, max_D=2,\n",
    "                                        max_q=2, max_Q=2,\n",
    "                                        trace=True, m=12,stepwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model wrapper is None, no model is trained.\n"
     ]
    }
   ],
   "source": [
    "tsfm = TSFM(df=df, n_pred_period=24, date_variable='beg_month', target_variable='product', value_variable='ro', stop_date=\"2020-03-01\", section_list=[\"HOME\", \"ACUTE\"], model_wrapper=None, input_is_monthly=True, output_is_monthly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "plot() missing 1 required positional argument: 'section'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-eb8b86f294aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtsfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: plot() missing 1 required positional argument: 'section'"
     ]
    }
   ],
   "source": [
    "tsfm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Applying anomaly filter...\n",
      "Performing stepwise search to minimize aic\n",
      " ARIMA(0,1,0)(0,1,0)[12]             : AIC=412.762, Time=0.06 sec\n",
      " ARIMA(1,1,0)(1,1,0)[12]             : AIC=415.533, Time=0.43 sec\n",
      " ARIMA(0,1,1)(0,1,1)[12]             : AIC=414.340, Time=0.40 sec\n",
      " ARIMA(0,1,0)(1,1,0)[12]             : AIC=414.748, Time=0.49 sec\n",
      " ARIMA(0,1,0)(0,1,1)[12]             : AIC=414.762, Time=0.22 sec\n",
      " ARIMA(0,1,0)(1,1,1)[12]             : AIC=416.718, Time=1.23 sec\n",
      " ARIMA(1,1,0)(0,1,0)[12]             : AIC=413.543, Time=0.12 sec\n",
      " ARIMA(0,1,1)(0,1,0)[12]             : AIC=412.348, Time=0.12 sec\n",
      " ARIMA(0,1,1)(1,1,0)[12]             : AIC=414.340, Time=0.72 sec\n",
      " ARIMA(0,1,1)(1,1,1)[12]             : AIC=inf, Time=1.38 sec\n",
      " ARIMA(1,1,1)(0,1,0)[12]             : AIC=413.196, Time=0.43 sec\n",
      " ARIMA(0,1,2)(0,1,0)[12]             : AIC=412.036, Time=0.44 sec\n",
      " ARIMA(0,1,2)(1,1,0)[12]             : AIC=413.947, Time=1.50 sec\n",
      " ARIMA(0,1,2)(0,1,1)[12]             : AIC=413.947, Time=1.32 sec\n",
      " ARIMA(0,1,2)(1,1,1)[12]             : AIC=415.972, Time=4.23 sec\n",
      " ARIMA(1,1,2)(0,1,0)[12]             : AIC=410.570, Time=0.51 sec\n",
      " ARIMA(1,1,2)(1,1,0)[12]             : AIC=412.548, Time=1.84 sec\n",
      " ARIMA(1,1,2)(0,1,1)[12]             : AIC=412.548, Time=0.88 sec\n",
      " ARIMA(1,1,2)(1,1,1)[12]             : AIC=inf, Time=0.89 sec\n",
      " ARIMA(2,1,2)(0,1,0)[12]             : AIC=412.298, Time=0.33 sec\n",
      " ARIMA(1,1,3)(0,1,0)[12]             : AIC=412.456, Time=0.83 sec\n",
      " ARIMA(0,1,3)(0,1,0)[12]             : AIC=411.931, Time=0.59 sec\n",
      " ARIMA(2,1,1)(0,1,0)[12]             : AIC=410.610, Time=0.31 sec\n",
      " ARIMA(2,1,3)(0,1,0)[12]             : AIC=inf, Time=1.79 sec\n",
      " ARIMA(1,1,2)(0,1,0)[12] intercept   : AIC=inf, Time=0.72 sec\n",
      "\n",
      "Best model:  ARIMA(1,1,2)(0,1,0)[12]          \n",
      "Total fit time: 21.851 seconds\n",
      "ic_list [[11905.93223872 13689.18077852]\n",
      " [12713.88976903 14844.56666957]\n",
      " [11365.23717042 13521.78522044]\n",
      " [12322.662515   14609.05057534]\n",
      " [12679.38210969 15028.95143712]\n",
      " [11322.22495543 13760.83970239]\n",
      " [13107.91699426 15618.24902834]\n",
      " [11314.45599547 13901.43223753]\n",
      " [11264.97721818 13922.91021105]\n",
      " [11715.09402728 14443.86531798]\n",
      " [10648.21751499 13445.16926292]\n",
      " [11305.12535943 14169.06644311]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    beg_month            ro\n",
       "0  2017-01-01  11260.000000\n",
       "1  2017-02-01  10906.000000\n",
       "2  2017-03-01  12657.000000\n",
       "3  2017-04-01  11245.000000\n",
       "4  2017-05-01  12505.000000\n",
       "5  2017-06-01  13015.000000\n",
       "6  2017-07-01  12051.000000\n",
       "7  2017-08-01  13442.000000\n",
       "8  2017-09-01  12377.000000\n",
       "9  2017-10-01  12783.000000\n",
       "10 2017-11-01  12226.000000\n",
       "11 2017-12-01  11993.000000\n",
       "12 2018-01-01  11990.000000\n",
       "13 2018-02-01  10944.000000\n",
       "14 2018-03-01  12720.000000\n",
       "15 2018-04-01  12085.000000\n",
       "16 2018-05-01  13223.000000\n",
       "17 2018-06-01  13027.000000\n",
       "18 2018-07-01  13266.000000\n",
       "19 2018-08-01  14358.000000\n",
       "20 2018-09-01  12463.000000\n",
       "21 2018-10-01  14154.000000\n",
       "22 2018-11-01  12756.000000\n",
       "23 2018-12-01  11957.000000\n",
       "24 2019-01-01  12493.000000\n",
       "25 2019-02-01  11554.000000\n",
       "26 2019-03-01  12903.000000\n",
       "27 2019-04-01  12931.000000\n",
       "28 2019-05-01  13587.000000\n",
       "29 2019-06-01  12418.000000\n",
       "30 2019-07-01  13355.000000\n",
       "31 2019-08-01  13787.000000\n",
       "32 2019-09-01  12452.000000\n",
       "33 2019-10-01  14285.000000\n",
       "34 2019-11-01  12524.000000\n",
       "35 2019-12-01  12513.000000\n",
       "36 2020-01-01  12997.000000\n",
       "37 2020-02-01  11965.000000\n",
       "38 2020-03-01  12655.000000\n",
       "39 2020-04-01  12797.556509\n",
       "40 2020-05-01  13779.228219\n",
       "41 2020-06-01  12530.000000\n",
       "42 2020-07-01  14009.000000\n",
       "43 2020-08-01  13518.000000\n",
       "44 2020-09-01  12541.532329\n",
       "45 2020-10-01  14414.000000\n",
       "46 2020-11-01  12468.000000\n",
       "47 2020-12-01  12878.000000\n",
       "48 2021-01-01  13079.479673"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>beg_month</th>\n      <th>ro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-01-01</td>\n      <td>11260.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-02-01</td>\n      <td>10906.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-03-01</td>\n      <td>12657.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-04-01</td>\n      <td>11245.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-05-01</td>\n      <td>12505.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2017-06-01</td>\n      <td>13015.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2017-07-01</td>\n      <td>12051.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2017-08-01</td>\n      <td>13442.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2017-09-01</td>\n      <td>12377.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2017-10-01</td>\n      <td>12783.000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2017-11-01</td>\n      <td>12226.000000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2017-12-01</td>\n      <td>11993.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2018-01-01</td>\n      <td>11990.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2018-02-01</td>\n      <td>10944.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2018-03-01</td>\n      <td>12720.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2018-04-01</td>\n      <td>12085.000000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2018-05-01</td>\n      <td>13223.000000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2018-06-01</td>\n      <td>13027.000000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2018-07-01</td>\n      <td>13266.000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2018-08-01</td>\n      <td>14358.000000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2018-09-01</td>\n      <td>12463.000000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2018-10-01</td>\n      <td>14154.000000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2018-11-01</td>\n      <td>12756.000000</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2018-12-01</td>\n      <td>11957.000000</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2019-01-01</td>\n      <td>12493.000000</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2019-02-01</td>\n      <td>11554.000000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2019-03-01</td>\n      <td>12903.000000</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2019-04-01</td>\n      <td>12931.000000</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2019-05-01</td>\n      <td>13587.000000</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>2019-06-01</td>\n      <td>12418.000000</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>2019-07-01</td>\n      <td>13355.000000</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2019-08-01</td>\n      <td>13787.000000</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>2019-09-01</td>\n      <td>12452.000000</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>2019-10-01</td>\n      <td>14285.000000</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2019-11-01</td>\n      <td>12524.000000</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>2019-12-01</td>\n      <td>12513.000000</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>2020-01-01</td>\n      <td>12997.000000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>2020-02-01</td>\n      <td>11965.000000</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>2020-03-01</td>\n      <td>12655.000000</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2020-04-01</td>\n      <td>12797.556509</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>2020-05-01</td>\n      <td>13779.228219</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>2020-06-01</td>\n      <td>12530.000000</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>2020-07-01</td>\n      <td>14009.000000</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>2020-08-01</td>\n      <td>13518.000000</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>2020-09-01</td>\n      <td>12541.532329</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>2020-10-01</td>\n      <td>14414.000000</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2020-11-01</td>\n      <td>12468.000000</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>2020-12-01</td>\n      <td>12878.000000</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>2021-01-01</td>\n      <td>13079.479673</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "tsfm.get_actual_data(\"HOME\", is_adjusted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}